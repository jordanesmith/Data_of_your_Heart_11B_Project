{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf57aba-06b2-4616-bc04-1cc140ee07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tf-NNN-build conda env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d46ac6d-3aee-4f80-8d00-d8ed05a9525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import os\n",
    "import neurokit2 as nk #TODO look into this algorithm\n",
    "from tqdm import tqdm\n",
    "import scipy.io\n",
    "from scipy.sparse import csc_matrix, spdiags\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f72019-61b3-4722-88dc-9cd86c9659e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding names of all test files ...\n",
      "all files found :)\n"
     ]
    }
   ],
   "source": [
    "print('finding names of all test files ...')\n",
    "all_files = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"F:\\\\DATA\\\\JSmith_SAFER_20220310\\\\raw_data\"):\n",
    "    for file in files:\n",
    "        if(file.endswith(\".dat\")):\n",
    "            all_files.append(os.path.join(root,file.split(\".dat\",2)[0]))\n",
    "print('all files found :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b147d2-0592-46f5-8400-7f9d5835927c",
   "metadata": {},
   "source": [
    "## Find the recordings which have been manually reviewed\n",
    "\n",
    "##### These lists are created in SAFERDataAnalysis.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe4e0be-2ab8-4e3a-b90a-430e1205e8ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4538, 1241, 2402)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "path_to_metadata_files = \"F:\\\\DATA\\\\JSmith_SAFER_20220310\\\\metadata\"\n",
    "\n",
    "with open(os.path.join(path_to_metadata_files, \"feas1\"), \"rb\") as file:   \n",
    "    meas_id_list_feas1 = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(path_to_metadata_files, \"feas2\"), \"rb\") as file:   \n",
    "    meas_id_list_feas2 = pickle.load(file)\n",
    "\n",
    "len(meas_id_list_feas1), len(meas_id_list_feas2), meas_id_list_feas1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d826e6-4e61-4601-b1f6-003bd48b2d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 185618/185618 [00:07<00:00, 24698.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4524, 1089)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feas1_filepaths_labelled = []\n",
    "feas2_filepaths_labelled = []\n",
    "\n",
    "for filepath in tqdm(all_files):\n",
    "    \n",
    "    if \"Feas1\" in filepath:\n",
    "        if int(filepath.split(\"saferF1_\",2)[1]) in meas_id_list_feas1:\n",
    "            feas1_filepaths_labelled.append(filepath)\n",
    "    \n",
    "    elif \"Feas2\" in filepath:\n",
    "        if int(filepath.split(\"saferF2_\",2)[1]) in meas_id_list_feas1:\n",
    "            feas2_filepaths_labelled.append(filepath)\n",
    "\n",
    "len(feas1_filepaths_labelled), len(feas2_filepaths_labelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5b4ea9-df4f-4b03-9a3c-b7bd6eaf7305",
   "metadata": {},
   "source": [
    "## Filtering and preprocessing, then saving the preprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f93a77-217d-47c7-943d-60e64657fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import baseline_als, butter_lowpass, butter_lowpass_filter\n",
    "\n",
    "# Filter requirements.\n",
    "order = 6\n",
    "fs = 30.0       # sample rate, Hz\n",
    "cutoff = 3.667  # desired cutoff frequency of the filter, Hz\n",
    "\n",
    "# Get the filter coefficients so we can check its frequency response.\n",
    "b, a = butter_lowpass(cutoff, fs, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b9ca2-e537-4a08-b790-44843cff6a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|████▌                                                        | 339/4524 [19:11<4:53:46,  4.21s/it]"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "# feas 1\n",
    "feas1_path_to_folder = \"F:\\\\DATA\\\\JSmith_SAFER_20220310\\\\preprocessed_labelled_data\\\\Feas1\"\n",
    "feas1_already_processed_files = [files for root, dirs, files in os.walk(feas1_path_to_folder)][0]\n",
    "feas1_processed_file_as_string = ''.join(item for item in feas1_already_processed_files)\n",
    "\n",
    "for test_file in tqdm(feas1_filepaths_labelled):\n",
    "    \n",
    "    # check not repeating process for already used file\n",
    "    test_file_name = test_file.split(\"\\\\\")[-1]    \n",
    "    if test_file_name not in feas1_processed_file_as_string:\n",
    "    \n",
    "        #preprocess\n",
    "        record = wfdb.rdrecord(test_file)\n",
    "        ecg_signal = record.p_signal.T[0]\n",
    "        signal_no_wander = ecg_signal - baseline_als(ecg_signal)\n",
    "        signal_smoothed = butter_lowpass_filter(signal_no_wander, 0.7, fs, order)\n",
    "\n",
    "        #save this file\n",
    "        filename = test_file.split(\"\\\\\")[-1]\n",
    "        dat_path = f\"{feas1_path_to_folder}\\\\{filename}.dat\"\n",
    "        np.savetxt(dat_path, signal_smoothed)\n",
    "        #copy over .hea file\n",
    "        shutil.copyfile(test_file + \".hea\", dat_path.replace(\".dat\", \".hea\"))\n",
    "\n",
    "        \n",
    "#feas 2\n",
    "feas2_path_to_folder = \"F:\\\\DATA\\\\JSmith_SAFER_20220310\\\\preprocessed_labelled_data\\\\Feas2\"\n",
    "feas2_already_processed_files = [files for root, dirs, files in os.walk(feas2_path_to_folder)][0]\n",
    "feas2_processed_file_as_string = ''.join(item for item in feas2_already_processed_files)\n",
    "\n",
    "for test_file in tqdm(feas2_filepaths_labelled):\n",
    "    \n",
    "    # check not repeating process for already used file\n",
    "    test_file_name = test_file.split(\"\\\\\")[-1]    \n",
    "    if test_file_name not in feas2_processed_file_as_string:\n",
    "    \n",
    "        #preprocess\n",
    "        record = wfdb.rdrecord(test_file)\n",
    "        ecg_signal = record.p_signal.T[0]\n",
    "        signal_no_wander = ecg_signal - baseline_als(ecg_signal)\n",
    "        signal_smoothed = butter_lowpass_filter(signal_no_wander, 0.7, fs, order)\n",
    "\n",
    "        #save this file\n",
    "        filename = test_file.split(\"\\\\\")[-1]\n",
    "        dat_path = f\"{feas1_path_to_folder}\\\\{filename}.dat\"\n",
    "        np.savetxt(dat_path, signal_smoothed)\n",
    "        #copy over .hea file\n",
    "        shutil.copyfile(test_file + \".hea\", dat_path.replace(\".dat\", \".hea\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c94b9-ec31-476f-b133-17117a1121df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
